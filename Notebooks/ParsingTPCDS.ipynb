{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-rough",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sqlparse\n",
    "#from sqlparse.sql import IdentifierList, Identifier\n",
    "#from sqlparse.tokens import Keyword, DML\n",
    "#from query_representation.utils import *\n",
    "\n",
    "from moz_sql_parser import parse\n",
    "#from mo_sql_parsing import parse as parse\n",
    "import os\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-focus",
   "metadata": {},
   "outputs": [],
   "source": [
    "QDIR = \"./queries/tpcds/all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "FNS = os.listdir(QDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(FNS))\n",
    "print(FNS[86])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqls = []\n",
    "for fn in FNS:\n",
    "    if \".sql\" not in fn:\n",
    "        continue\n",
    "    if \"all\" in fn:\n",
    "        continue\n",
    "    fn = os.path.join(QDIR, fn)\n",
    "    with open(fn, \"r\") as f:\n",
    "        sql = f.read()\n",
    "#     if \"like\" in sql.lower():\n",
    "#         print(sql)\n",
    "    sqls.append(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sqls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(sqls[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-facing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for si, q in enumerate(sqls):\n",
    "#     if \"q4\" in q.lower():\n",
    "#         print(si)\n",
    "#         print(q)\n",
    "#         print(\"********************************\")\n",
    "#         #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opponent-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sql = sqls[50]\n",
    "sql = sqls[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-jefferson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-official",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = parse(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-clock",
   "metadata": {},
   "source": [
    "# Q87 very hard to parse;\n",
    "### TODO: maybe queries w/ multiple subqueries, we just try to get each select block and parse them individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-experiment",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql4 = \"\"\"-- q87\n",
    "\n",
    "\n",
    "select count(*) \n",
    "from (select distinct c_last_name, c_first_name, d_date\n",
    "       from store_sales, date_dim, customer  -- skan_memo_stash_87\n",
    "       where store_sales.ss_sold_date_sk = date_dim.d_date_sk\n",
    "         and store_sales.ss_customer_sk = customer.c_customer_sk\n",
    "         and d_month_seq between 1212 and 1212+11)\n",
    "       except\n",
    "      (select distinct c_last_name, c_first_name, d_date\n",
    "       from catalog_sales, date_dim, customer\n",
    "       where catalog_sales.cs_sold_date_sk = date_dim.d_date_sk\n",
    "         and catalog_sales.cs_bill_customer_sk = customer.c_customer_sk\n",
    "         and d_month_seq between 1212 and 1212+11)\n",
    "       except\n",
    "      (select distinct c_last_name, c_first_name, d_date\n",
    "       from web_sales, date_dim, customer\n",
    "       where web_sales.ws_sold_date_sk = date_dim.d_date_sk\n",
    "         and web_sales.ws_bill_customer_sk = customer.c_customer_sk\n",
    "         and d_month_seq between 1212 and 1212+11)\n",
    "cool_cust\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sql4 = \"\"\"-- q87\n",
    "\n",
    "\n",
    "select count(*) \n",
    "from ((select distinct c_last_name, c_first_name, d_date\n",
    "       from store_sales, date_dim, customer  -- skan_memo_stash_87\n",
    "       where store_sales.ss_sold_date_sk = date_dim.d_date_sk\n",
    "         and store_sales.ss_customer_sk = customer.c_customer_sk\n",
    "         and d_month_seq between 1212 and 1212+11)\n",
    "       except\n",
    "      (select distinct c_last_name, c_first_name, d_date\n",
    "       from catalog_sales, date_dim, customer\n",
    "       where catalog_sales.cs_sold_date_sk = date_dim.d_date_sk\n",
    "         and catalog_sales.cs_bill_customer_sk = customer.c_customer_sk\n",
    "         and d_month_seq between 1212 and 1212+11))\n",
    "cool_cust\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# sql4 = \"\"\"-- q87\n",
    "\n",
    "\n",
    "# select count(*) \n",
    "# from (select distinct c_last_name, c_first_name, d_date\n",
    "#        from store_sales, date_dim, customer  -- skan_memo_stash_87\n",
    "#        where store_sales.ss_sold_date_sk = date_dim.d_date_sk\n",
    "#          and store_sales.ss_customer_sk = customer.c_customer_sk\n",
    "#          and d_month_seq between 1212 and 1212+11)\n",
    "# cool_cust\n",
    "# \"\"\"\n",
    "parse(sql4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-selling",
   "metadata": {},
   "source": [
    "# Fix for Q40, change order of from tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sql3 = \"\"\"select top 100 \n",
    "   w_state\n",
    "  ,i_item_id\n",
    "  ,sum(case when (cast(d_date as date) < cast ('1998-04-08' as date)) \n",
    "        then cs_sales_price - coalesce(cr_refunded_cash,0) else 0 end) as sales_before\n",
    "  ,sum(case when (cast(d_date as date) >= cast ('1998-04-08' as date)) \n",
    "        then cs_sales_price - coalesce(cr_refunded_cash,0) else 0 end) as sales_after\n",
    " from\n",
    "   warehouse  -- skan_memo_stash_40\n",
    "  ,item\n",
    "  ,date_dim\n",
    "  ,catalog_sales left outer join catalog_returns on\n",
    "       (cs_order_number = cr_order_number \n",
    "        and cs_item_sk = cr_item_sk)\n",
    "\n",
    " where\n",
    "     i_current_price between 0.99 and 1.49\n",
    " and i_item_sk          = cs_item_sk\n",
    " and cs_warehouse_sk    = w_warehouse_sk \n",
    " and cs_sold_date_sk    = d_date_sk\n",
    " and d_date >= dateadd(dd, -30, '1998-04-08')\n",
    " and d_date <= dateadd(dd, 30, '1998-04-08') \n",
    " group by\n",
    "    w_state,i_item_id\n",
    " order by w_state,i_item_id\"\"\"\n",
    "parse(sql3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-election",
   "metadata": {},
   "source": [
    "# replace intersect by union seems to work for now;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql2 = \"\"\"select top 100 count(*) from (\n",
    "    select distinct c_last_name, c_first_name, d_date\n",
    "    from store_sales, date_dim, customer -- skan_memo_stash_38\n",
    "          where store_sales.ss_sold_date_sk = date_dim.d_date_sk\n",
    "      and store_sales.ss_customer_sk = customer.c_customer_sk\n",
    "      and d_month_seq between 1212 and 1212 + 11) test\"\"\"\n",
    "sql2 = \"\"\"select top 100 count(*) from (\n",
    "    select distinct c_last_name, c_first_name, d_date\n",
    "    from store_sales, date_dim, customer -- skan_memo_stash_38\n",
    "          where store_sales.ss_sold_date_sk = date_dim.d_date_sk\n",
    "      and store_sales.ss_customer_sk = customer.c_customer_sk\n",
    "      and d_month_seq between 1212 and 1212 + 11\n",
    "  union\n",
    "    select distinct c_last_name, c_first_name, d_date\n",
    "    from catalog_sales, date_dim, customer\n",
    "          where catalog_sales.cs_sold_date_sk = date_dim.d_date_sk\n",
    "      and catalog_sales.cs_bill_customer_sk = customer.c_customer_sk\n",
    "      and d_month_seq between 1212 and 1212 + 11) tmp\"\"\"\n",
    "parse(sql2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-wrist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "#p2[\"with\"][\"value\"][\"from\"][\"value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "domestic-occupation",
   "metadata": {},
   "source": [
    "# Example commands exploring sample query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-english",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p2.keys())\n",
    "print(p2[\"from\"])\n",
    "print(\"SELECT: \", p2[\"select\"])\n",
    "print(\"WHERE: \", p2[\"where\"])\n",
    "\n",
    "# LT1\n",
    "#print(p2[\"where\"][\"and\"][-1][\"lt\"])\n",
    "# EQ1, join\n",
    "print(p2[\"where\"][\"and\"][0][\"eq\"])\n",
    "\n",
    "# element 0: column name / or operations on it, and element 1 is constant / other col;\n",
    "for x in p2[\"where\"][\"and\"]:\n",
    "    print(x)\n",
    "\n",
    "# name = sales_detail is an alias for a large-ass query / subquery; \n",
    "# print(len(p2[\"with\"][\"value\"][\"from\"][\"value\"][\"union\"]))\n",
    "\n",
    "# for x in p2[\"with\"][\"value\"][\"from\"][\"value\"][\"union\"]:\n",
    "#     print(x.keys())\n",
    "#     print(x[\"where\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_predicates(parsed_sql):\n",
    "    alldata = {}\n",
    "    \n",
    "    def handle_ops(data, key):\n",
    "        #print(\"key: \", key)\n",
    "        #print(\"data: \", data)\n",
    "#         if key == \"exists\":\n",
    "#             print(\"TODO: handle exists\")\n",
    "#             return\n",
    "#         if data[key].keys()[0] == \"exists\":\n",
    "#             print(\"handle not exists\")\n",
    "#             return\n",
    "        #print(data, key)\n",
    "        if isinstance(data[key], dict):\n",
    "            print(\"FIX handle ops:\")\n",
    "            print(data)\n",
    "            return\n",
    "        col1 = data[key][0]\n",
    "        if isinstance(col1, list) or isinstance(col1, dict):\n",
    "            # TODO: extract the column thing happening here\n",
    "            col1 = str(col1)\n",
    "            tablename = \"complex\"\n",
    "        elif \".\" in col1:\n",
    "            #print(col1)\n",
    "            tablename = col1[0:col1.find(\".\")]\n",
    "            col1 = col1[col1.find(\".\")+1:]\n",
    "            #print(tablename, col1)\n",
    "        else:\n",
    "            tablename = \"X\"\n",
    "            \n",
    "        if tablename not in alldata:\n",
    "            alldata[tablename] = {}\n",
    "        \n",
    "        if col1 not in alldata[tablename]:\n",
    "            alldata[tablename][col1] = {}\n",
    "            \n",
    "        if key not in alldata[tablename][col1]:\n",
    "            alldata[tablename][col1][key] = set()\n",
    "        \n",
    "        curkeydata = alldata[tablename][col1][key]\n",
    "            \n",
    "        if key == \"eq\" or key == \"neq\":\n",
    "            #assert len(data[\"eq\"]) == 2\n",
    "            assert len(data[key]) == 2\n",
    "            #val2 = data[\"eq\"][1]\n",
    "            val2 = data[key][1]\n",
    "            if isinstance(val2, int) or isinstance(val2, float):\n",
    "                curkeydata.add(val2)\n",
    "            elif isinstance(val2, dict):\n",
    "                #print(type(val2))\n",
    "                #print(\"Val2: \", val2)\n",
    "                #assert len(val2) == 1\n",
    "                #print(val2.keys())\n",
    "                #print(data)\n",
    "                #alldata[tablename][col1].add(val2[\"literal\"])\n",
    "                # TODO: can have things like literal etc.\n",
    "                #print(val2)\n",
    "                #if val2.keys\n",
    "                #print(len(val2))\n",
    "                #print(val2)\n",
    "                if len(val2) > 1:\n",
    "                    #print(\"**SKIPPING handleobj2**\")\n",
    "                    handle_obj(val2)\n",
    "                else:\n",
    "                    curkeydata.add(str(val2))\n",
    "            else:\n",
    "                #print(\"JOIN?\")\n",
    "                #print(data)\n",
    "                #print(val2)\n",
    "                #assert \".\" in val2\n",
    "                return\n",
    "            \n",
    "        elif key in [\"lt\", \"gt\", \"lte\", \"gte\"]:\n",
    "            assert len(data[key]) == 2\n",
    "            val2 = data[key][1]\n",
    "            curkeydata.add(str(val2))\n",
    "            return\n",
    "        else:\n",
    "            print(\"UNKNOWN\")\n",
    "            print(key)\n",
    "        \n",
    "    def handle_obj(obj):\n",
    "        if isinstance(obj, list):\n",
    "            for obj1 in obj:\n",
    "                handle_obj(obj1)\n",
    "\n",
    "        elif isinstance(obj, dict):\n",
    "            for k in obj:\n",
    "                # check for from + where in joins\n",
    "                #print(\"k: \", k)\n",
    "                if k == \"where\":\n",
    "                    for k2 in obj[k]:\n",
    "                        if k2 == \"or\":\n",
    "                            pass\n",
    "                            #print(\"!!OR!!\")\n",
    "                            #print(obj)\n",
    "                        elif k2 == \"and\":\n",
    "                            for curpred in obj[k][k2]:\n",
    "                                #print(\"curpred: \", curpred)\n",
    "                                for curpredk in curpred:\n",
    "                                    #print(\"ck: \", curpredk)\n",
    "                                    #print(\"going to call handle_ops1\")\n",
    "                                    \n",
    "                                    handle_ops(curpred, curpredk)\n",
    "                        elif k2 in [\"eq\", \"lt\", \"lte\", \"gt\", \"gte\"]:\n",
    "                            handle_ops(obj[k], k2)\n",
    "                        else:\n",
    "                            pass\n",
    "                            #print(k2)\n",
    "                else:\n",
    "                    #print(\"going to call handleobj2\")\n",
    "                    handle_obj(obj[k])\n",
    "        else:\n",
    "            pass\n",
    "                    \n",
    "    handle_obj(parsed_sql)\n",
    "    return alldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "for si, sql in enumerate(sqls):\n",
    "    if \"intersect\" in sql.lower():\n",
    "        print(si, \" INTERSECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = parse_predicates(p2)\n",
    "for k,v in ret.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-support",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "alldfdata = defaultdict(list)\n",
    "for si, sql in enumerate(sqls):\n",
    "    #print(sql)\n",
    "#     if \"q80\" in sql:\n",
    "#         print(\"Skipping Query 89\")\n",
    "#         continue\n",
    "    \n",
    "    # intersect queries\n",
    "    if si in [32, 84, 89, 91]:\n",
    "        continue\n",
    "    \n",
    "    if si in [27, 32, 45, 50, 56, 58, 78, 84, 85, 90, 92]:\n",
    "    #if si in [27, 45, 50]:   \n",
    "        continue\n",
    "        \n",
    "    if si in [22, 23, 31]:\n",
    "        continue\n",
    "    \n",
    "    print(\"Query: \", si)\n",
    "    parsed_sql = parse(sql)\n",
    "    curdata = parse_predicates(parsed_sql)\n",
    "#     if si > 1:\n",
    "#         break\n",
    "    for inp in curdata:\n",
    "        for col in curdata[inp]:\n",
    "            alldfdata[\"input\"].append(inp)\n",
    "            alldfdata[\"column\"].append(col)\n",
    "            for op, vals in curdata[inp][col].items():\n",
    "                if op == \"eq\":\n",
    "                    alldfdata[\"discrete_ops\"].append(1)\n",
    "                else:\n",
    "                    alldfdata[\"discrete_ops\"].append(0)\n",
    "                \n",
    "                if op == \"lt\":\n",
    "                    alldfdata[\"cont_ops\"].append(1)\n",
    "                else:\n",
    "                    alldfdata[\"cont_ops\"].append(0)\n",
    "                \n",
    "                # TODO: parse in better; can we parse these values somehow?\n",
    "                if op == \"in\":\n",
    "                    alldfdata[\"discrete_ops\"].append(1)\n",
    "                    alldfdata[\"in_ops\"].append(1)\n",
    "                else:\n",
    "                    alldfdata[\"in_ops\"].append(0)\n",
    "                    \n",
    "                if op == \"like\":\n",
    "                    alldfdata[\"like_ops\"].append(1)\n",
    "                else:\n",
    "                    alldfdata[\"like_ops\"].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(alldfdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"equal_dates\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(df[[\"like_ops\", \"discrete_ops\", \"cont_ops\", \"in_ops\"]].\\\n",
    "     describe(percentiles=[0.9,0.99]).reset_index().to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-applicant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
