{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from cardinality_estimation.featurizer import Featurizer\n",
    "from query_representation.query import load_qrep\n",
    "from cardinality_estimation.dataset import *\n",
    "from torch.utils import data\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-separate",
   "metadata": {},
   "source": [
    "# Setup file paths / Download query data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import errno\n",
    "def make_dir(directory):\n",
    "    try:\n",
    "        os.makedirs(directory)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINDIR = os.path.join(os.path.join(\"..\", \"queries\"), \"imdb\")\n",
    "TESTDIR = os.path.join(os.path.join(\"..\", \"queries\"), \"imdb-unique-plans\")\n",
    "RESULTDIR = os.path.join(\"..\", \"results\")\n",
    "make_dir(RESULTDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-collaboration",
   "metadata": {},
   "source": [
    "# Query loading helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qdata(fns):\n",
    "    qreps = []\n",
    "    for qfn in fns:\n",
    "        qrep = load_qrep(qfn)\n",
    "        # TODO: can do checks like no queries with zero cardinalities etc.\n",
    "        qreps.append(qrep)\n",
    "        template_name = os.path.basename(os.path.dirname(qfn))\n",
    "        qrep[\"name\"] = os.path.basename(qfn)\n",
    "        qrep[\"template_name\"] = template_name\n",
    "    return qreps\n",
    "\n",
    "def get_query_fns(basedir, template_fraction=1.0, sel_templates=None):\n",
    "    fns = []\n",
    "    tmpnames = list(glob.glob(os.path.join(basedir, \"*\")))\n",
    "    assert template_fraction <= 1.0\n",
    "    \n",
    "    for qi,qdir in enumerate(tmpnames):\n",
    "        if os.path.isfile(qdir):\n",
    "            continue\n",
    "        template_name = os.path.basename(qdir)\n",
    "        if sel_templates is not None and template_name not in sel_templates:\n",
    "            continue\n",
    "        \n",
    "        # let's first select all the qfns we are going to load\n",
    "        qfns = list(glob.glob(os.path.join(qdir, \"*.pkl\")))\n",
    "        qfns.sort()\n",
    "        num_samples = max(int(len(qfns)*template_fraction), 1)\n",
    "        random.seed(1234)\n",
    "        qfns = random.sample(qfns, num_samples)\n",
    "        fns += qfns\n",
    "    return fns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-waterproof",
   "metadata": {},
   "source": [
    "# Evaluation helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-omaha",
   "metadata": {},
   "source": [
    "# Load queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-arena",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set template_fraction <= 1.0 to test quickly w/ smaller datasets\n",
    "# train_qfns = get_query_fns(TRAINDIR, template_fraction = 0.001)\n",
    "# val_qfns = get_query_fns(VALDIR, template_fraction = 1.0)\n",
    "# test_qfns = get_query_fns(TESTDIR, template_fraction = 1.0)\n",
    "\n",
    "#qfns = get_query_fns(TRAINDIR, template_fraction = 1.0, sel_templates=None)\n",
    "\n",
    "qfns = get_query_fns(TRAINDIR, template_fraction = 1.0, sel_templates=\"1a\")\n",
    "qdata = load_qdata(qfns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a8a538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy\n",
    "\n",
    "subplan_data = defaultdict(list)\n",
    "\n",
    "rowkeys = set()\n",
    "for qi, qrep in enumerate(qdata):\n",
    "    for node in qrep[\"subset_graph\"].nodes():\n",
    "        rowkeys.add(node)\n",
    "rowkeys = list(rowkeys)\n",
    "rowkeys.sort()\n",
    "rowidxs = {rk:ri for ri,rk in enumerate(rowkeys)}\n",
    "#print(rowidxs)\n",
    "mat = np.zeros((len(rowidxs), len(qdata)))\n",
    "\n",
    "for qi, qrep in enumerate(qdata):\n",
    "    for node in qrep[\"subset_graph\"].nodes():\n",
    "        truec = qrep[\"subset_graph\"].nodes()[node][\"cardinality\"][\"actual\"]\n",
    "        mat[rowidxs[node], qi] = truec\n",
    "        \n",
    "mat = mat.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c4d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1bd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "P, S, Q = np.linalg.svd(mat, full_matrices=False)\n",
    "print(S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "S.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76cd171",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(S, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8f2b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank = np.sum(S > 1e10)\n",
    "# rank\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30052715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#sns.lineplot(np.log(S))\n",
    "sns.lineplot(x=list(range(len(S))), y=S)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a94323",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds = np.cumsum(S) / np.sum(S)\n",
    "r90 = np.min(np.where(cds > 0.90))\n",
    "r90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b8d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def omega_approx(beta):\n",
    "    \"\"\"Return an approximate omega value for given beta. Equation (5) from Gavish 2014.\"\"\"\n",
    "    return 0.56 * beta**3 - 0.95 * beta**2 + 1.82 * beta + 1.43\n",
    "\n",
    "def svht(X, sigma=None, sv=None):\n",
    "    \"\"\"Return the optimal singular value hard threshold (SVHT) value.\n",
    "    `X` is any m-by-n matrix. `sigma` is the standard deviation of the \n",
    "    noise, if known. Optionally supply the vector of singular values `sv`\n",
    "    for the matrix (only necessary when `sigma` is unknown). If `sigma`\n",
    "    is unknown and `sv` is not supplied, then the method automatically\n",
    "    computes the singular values.\"\"\"\n",
    "\n",
    "    try:\n",
    "        m,n = sorted(X.shape) # ensures m <= n\n",
    "    except:\n",
    "        raise ValueError('invalid input matrix')\n",
    "    beta = m / n # ratio between 0 and 1\n",
    "    if sigma is None: # sigma unknown\n",
    "        if sv is None:\n",
    "            sv = svdvals(X)\n",
    "        sv = np.squeeze(sv)\n",
    "        if sv.ndim != 1:\n",
    "            raise ValueError('vector of singular values must be 1-dimensional')\n",
    "        return np.median(sv) * omega_approx(beta)\n",
    "    else: # sigma known\n",
    "        return lambda_star(beta) * np.sqrt(n) * sigma\n",
    "\n",
    "# find tau star hat when sigma is unknown\n",
    "# tau = svht(D, sv=sv)\n",
    "\n",
    "# # find tau star when sigma is known\n",
    "# tau = svht(D, sigma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a079818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = svht(mat, sv=S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34791e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b54de",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = np.sum(S > tau)\n",
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d0eb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
