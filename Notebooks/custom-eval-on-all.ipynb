{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display_html\n",
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-exhibition",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = \"/Users/pari/Desktop/\"\n",
    "#/Users/pari/Desktop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgruns = api.runs(\"pari/MyCEB\",\n",
    "    {\"$and\": [\n",
    "       {\"config.algs\": \"postgres\"},\n",
    "       {\"config.val_size\":0},\n",
    "       {\"config.test_size\":0},\n",
    "       {\"config.query_templates\":\"all\"},\n",
    "       {\"config.query_dir\":\"queries/imdb-unique-plans\"},\n",
    "       {\"config.num_samples_per_template\":-1},\n",
    "       {\"$or\": [\n",
    "           {\"tags\":\"v14\"},\n",
    "       ]}\n",
    "    ]\n",
    "    })\n",
    "\n",
    "print(f\"Found {len(pgruns)} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#summary_list, config_list, name_list = [], [], []\n",
    "#TAGS = [\"baselines\", \"baseline\", \"best_model_0.2\", \"best_model\"]\n",
    "pgdfs = []\n",
    "\n",
    "for run in pgruns:\n",
    "    skip = False\n",
    "    if skip:\n",
    "        continue\n",
    "    if run.State != \"finished\":\n",
    "        continue\n",
    "    \n",
    "    data = defaultdict(list)\n",
    "    data[\"Tags\"].append(run.Tags)\n",
    "    data[\"name\"].append(run.name)\n",
    "    \n",
    "    \n",
    "    for k,v in run.config.items():\n",
    "        if not k.startswith(\"_\") or not k.contains(\"/\"):\n",
    "            data[k].append(v)\n",
    "\n",
    "    for k,v in run.summary._json_dict.items():\n",
    "        if k.startswith(\"_\"):\n",
    "            continue\n",
    "        if \"/\" in k:\n",
    "            continue\n",
    "        data[k].append(v)\n",
    "        \n",
    "    pgdfs.append(pd.DataFrame(data))\n",
    "\n",
    "print(\"took: \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgdf = pd.concat(pgdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pgdf = pgdf[~pgdf[\"Final-Relative-TotalPPCost-train-2a\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = api.runs(\"pari/MyCEB\",\n",
    "    {\"$and\": [\n",
    "       {\"config.algs\": \"mscn\"},\n",
    "       {\"config.train_test_split_kind\":\"custom\"},\n",
    "       {\"config.test_tmps\":\"all\"},\n",
    "       {\"config.query_dir\":\"queries/imdb-unique-plans\"},\n",
    "       {\"config.no_regex_templates\":1},\n",
    "       {\"config.embedding_fn\":\"none\"},\n",
    "       {\"config.feat_separate_alias\":0},\n",
    "       {\"$or\": [ \n",
    "           {\"config.subplan_level_outputs\":0},\n",
    "           {\"config.subplan_level_outputs\":None},\n",
    "       ]},\n",
    "       {\"$or\": [ \n",
    "           {\"config.training_opt\":\"\"},\n",
    "           {\"config.training_opt\":\"none\"},\n",
    "           {\"config.training_opt\":None},\n",
    "       ]},\n",
    "       {\"config.weight_decay\":0},\n",
    "       {\"$or\": [\n",
    "           {\"tags\":\"v15\"},\n",
    "       ]}\n",
    "    ]\n",
    "    })\n",
    "\n",
    "print(f\"Found {len(runs)} runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#summary_list, config_list, name_list = [], [], []\n",
    "#TAGS = [\"baselines\", \"baseline\", \"best_model_0.2\", \"best_model\"]\n",
    "dfs = []\n",
    "\n",
    "for run in runs:\n",
    "    skip = False\n",
    "    if skip:\n",
    "        continue\n",
    "    if run.State != \"finished\":\n",
    "        continue\n",
    "    \n",
    "    data = defaultdict(list)\n",
    "    data[\"Tags\"].append(run.Tags)\n",
    "    data[\"name\"].append(run.name)\n",
    "    \n",
    "    \n",
    "    for k,v in run.config.items():\n",
    "        if not k.startswith(\"_\") or not k.contains(\"/\"):\n",
    "            data[k].append(v)\n",
    "\n",
    "    for k,v in run.summary._json_dict.items():\n",
    "        if k.startswith(\"_\"):\n",
    "            continue\n",
    "        if \"/\" in k:\n",
    "            continue\n",
    "        data[k].append(v)\n",
    "        \n",
    "    dfs.append(pd.DataFrame(data))\n",
    "\n",
    "print(\"took: \", time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-topic",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(df[\"table_features\"]))\n",
    "print(set(df[\"join_features\"]))\n",
    "print(set(df[\"set_column_feature\"]))\n",
    "print(set(df[\"max_discrete_featurizing_buckets\"]))\n",
    "#print(set(df[\"mask_unseen_subplans\"]))\n",
    "print(set(df[\"onehot_dropout\"]))\n",
    "#print(set(df[\"onehot_mask_truep\"]))\n",
    "print(set(df[\"loss_func_name\"]))\n",
    "print(set(df[\"hidden_layer_size\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_featurization(row):\n",
    "    ret = \"\"\n",
    "    if row[\"table_features\"] == 1 \\\n",
    "        and row[\"set_column_feature\"] in [\"1\", 1, \"onehot\"] \\\n",
    "        and row[\"join_features\"] in [\"1\", 1, \"onehot\"] \\\n",
    "        and row[\"loss_func_name\"] == \"mse\" \\\n",
    "        and row[\"ynormalization\"] == \"log\" \\\n",
    "        and row[\"load_query_together\"] == 0 \\\n",
    "        and row[\"weight_decay\"] == 0 \\\n",
    "        and row[\"onehot_dropout\"] == 0:\n",
    "        if row[\"sample_bitmap\"] == 0 and row[\"max_discrete_featurizing_buckets\"] == 10 and \\\n",
    "            row[\"max_like_featurizing_buckets\"] == 10:\n",
    "            ret = \"Default\"\n",
    "        elif row[\"sample_bitmap\"] == 1:\n",
    "            ret = \"Default + Sample Bitmap-\" \\\n",
    "            + str(row[\"max_discrete_featurizing_buckets\"]) \\\n",
    "            + str(row[\"max_like_featurizing_buckets\"])\n",
    "        else:\n",
    "            ret = \"Default (unknown)\"\n",
    "    elif row[\"table_features\"] == 1 \\\n",
    "        and row[\"set_column_feature\"] in [\"1\", 1, \"onehot\"] \\\n",
    "        and row[\"join_features\"] in [\"1\", 1, \"onehot\"] \\\n",
    "        and row[\"max_discrete_featurizing_buckets\"] == 1 \\\n",
    "        and row[\"max_like_featurizing_buckets\"] == 1 \\\n",
    "        and row[\"loss_func_name\"] == \"mse\" \\\n",
    "        and row[\"load_query_together\"] == 0 \\\n",
    "        and row[\"weight_decay\"] == 0 \\\n",
    "        and row[\"onehot_dropout\"] == 0:\n",
    "        ret = \"Default (onehot, no-buckets)\"\n",
    "    elif row[\"table_features\"] == 1 \\\n",
    "        and row[\"set_column_feature\"] in [\"1\", 1, \"onehot\"] \\\n",
    "        and row[\"join_features\"] in [\"1\", 1, \"onehot\"] \\\n",
    "        and row[\"max_discrete_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"max_like_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"loss_func_name\"] == \"mse\" \\\n",
    "        and row[\"load_query_together\"] == 0 \\\n",
    "        and row[\"weight_decay\"] == 0 \\\n",
    "        and row[\"onehot_dropout\"] == 2 \\\n",
    "        and row[\"heuristic_features\"] == 1:\n",
    "        ret = \"Default-dropout-\" + str(row[\"onehot_mask_truep\"])\n",
    "    elif row[\"table_features\"] == 1 \\\n",
    "        and row[\"set_column_feature\"] in [\"1\", 1, \"onehot\"] \\\n",
    "        and row[\"join_features\"] in [\"1\", 1, \"onehot\"] \\\n",
    "        and row[\"max_discrete_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"max_like_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"loss_func_name\"] == \"flowloss\" \\\n",
    "        and row[\"weight_decay\"] == 0 \\\n",
    "        and row[\"normalize_flow_loss\"] == 1 \\\n",
    "        and row[\"flow_features\"] == 1:\n",
    "        ret = \"FlowLoss (onehot)\"\n",
    "    elif row[\"table_features\"] == 1 \\\n",
    "        and row[\"set_column_feature\"] == \"onehot-stats\" \\\n",
    "        and row[\"join_features\"] == \"onehot-stats\" \\\n",
    "        and row[\"max_discrete_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"max_like_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"loss_func_name\"] == \"flowloss\" \\\n",
    "        and row[\"weight_decay\"] == 0 \\\n",
    "        and row[\"normalize_flow_loss\"] == 1 \\\n",
    "        and row[\"flow_features\"] == 1:\n",
    "        ret = \"FlowLoss (onehot-stats)\"\n",
    "    elif row[\"table_features\"] == 1 \\\n",
    "        and row[\"set_column_feature\"] == \"onehot-stats\" \\\n",
    "        and row[\"join_features\"] == \"onehot-stats\" \\\n",
    "        and row[\"max_discrete_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"max_like_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"loss_func_name\"] == \"flowloss\" \\\n",
    "        and row[\"weight_decay\"] == 0 \\\n",
    "        and row[\"normalize_flow_loss\"] == 1 \\\n",
    "        and row[\"flow_features\"] == 1 \\\n",
    "        and row[\"onehot_dropout\"] == 2:\n",
    "        ret = \"FlowLoss (onehot-stats-dropout)\"\n",
    "    elif row[\"table_features\"] == 1 \\\n",
    "        and row[\"set_column_feature\"] in [\"1\", 1, \"onehot\"] \\\n",
    "        and row[\"join_features\"] in [\"1\", 1, \"onehot\"] \\\n",
    "        and row[\"max_discrete_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"max_like_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"loss_func_name\"] == \"flowloss\" \\\n",
    "        and row[\"weight_decay\"] == 0 \\\n",
    "        and row[\"normalize_flow_loss\"] == 0 \\\n",
    "        and row[\"flow_features\"] == 1:\n",
    "        ret = \"FlowLoss2 (onehot)\"\n",
    "    elif row[\"table_features\"] == 1 \\\n",
    "        and row[\"set_column_feature\"] in [\"1\", 1, \"onehot\"] \\\n",
    "        and row[\"join_features\"] in [\"1\", 1, \"onehot\"] \\\n",
    "        and row[\"max_discrete_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"max_like_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"loss_func_name\"] == \"mse+ranknet\" \\\n",
    "        and row[\"load_query_together\"] == 1:\n",
    "        ret = \"MSE+ranknet\"\n",
    "    \n",
    "    elif row[\"table_features\"] == 1 \\\n",
    "        and row[\"set_column_feature\"] == \"onehot-stats\" \\\n",
    "        and row[\"join_features\"] == \"onehot-stats\" \\\n",
    "        and row[\"loss_func_name\"] == \"mse\" \\\n",
    "        and row[\"weight_decay\"] == 0 \\\n",
    "        and row[\"onehot_dropout\"] == 2:\n",
    "        if row[\"sample_bitmap\"] == 1:\n",
    "            ret = \"Onehot-Stats-Dropout-Bitmap-\" + \\\n",
    "            str(row[\"max_discrete_featurizing_buckets\"]) + \"-\" + \\\n",
    "            str(row[\"max_like_featurizing_buckets\"]) + \"-\" + \\\n",
    "            str(row[\"max_epochs\"]) + \"-\" + \\\n",
    "            str(row[\"onehot_mask_truep\"])\n",
    "        else:\n",
    "            ret = \"Onehot-Stats-Dropout-\" + str(row[\"max_discrete_featurizing_buckets\"]) + \"-\" +\\\n",
    "            str(row[\"max_like_featurizing_buckets\"]) + \"-\" + \\\n",
    "            str(row[\"max_epochs\"]) + \"-\" + \\\n",
    "            str(row[\"onehot_mask_truep\"])\n",
    "        \n",
    "    elif row[\"table_features\"] == 1 \\\n",
    "        and row[\"set_column_feature\"] == \"onehot\" \\\n",
    "        and row[\"join_features\"] == \"onehot\" \\\n",
    "        and row[\"loss_func_name\"] == \"mse\" \\\n",
    "        and row[\"weight_decay\"] == 0 \\\n",
    "        and row[\"onehot_dropout\"] == 2:\n",
    "        if row[\"sample_bitmap\"] == 1:\n",
    "            ret = \"Onehot-Dropout-Bitmap-\" + \\\n",
    "            str(row[\"max_discrete_featurizing_buckets\"]) + \"-\" + \\\n",
    "            str(row[\"max_like_featurizing_buckets\"]) + \"-\" + \\\n",
    "            str(row[\"max_epochs\"]) + \"-\" + \\\n",
    "            str(row[\"onehot_mask_truep\"])\n",
    "        else:\n",
    "            ret = \"Onehot-Dropout-\" + str(row[\"max_discrete_featurizing_buckets\"]) + \"-\" +\\\n",
    "            str(row[\"max_like_featurizing_buckets\"]) + \"-\" + \\\n",
    "            str(row[\"max_epochs\"]) + \"-\" + \\\n",
    "            str(row[\"onehot_mask_truep\"])\n",
    "        \n",
    "    elif row[\"table_features\"] == 1 \\\n",
    "        and row[\"set_column_feature\"] == \"onehot-stats\" \\\n",
    "        and row[\"join_features\"] == \"onehot-stats\" \\\n",
    "        and row[\"max_discrete_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"max_like_featurizing_buckets\"] == 10 \\\n",
    "        and row[\"loss_func_name\"] == \"mse\" \\\n",
    "        and row[\"weight_decay\"] == 0 \\\n",
    "        and row[\"onehot_dropout\"] > 0 \\\n",
    "        and row[\"max_epochs\"] == 20:\n",
    "        ret = \"Onehot-Stats-dropout\" + str(row[\"onehot_dropout\"])\n",
    "    else:\n",
    "        ret = \"unknown\"\n",
    "    \n",
    "    if row[\"feat_separate_like_ests\"] == 1:\n",
    "        ret += \"-sepLike\"\n",
    "    \n",
    "    if row[\"feat_true_base_cards\"] == 1:\n",
    "        ret += \"-trueBase\"\n",
    "        \n",
    "    if row[\"max_discrete_featurizing_buckets\"] == 30:\n",
    "        ret += \"-bins30\"\n",
    "        \n",
    "    if row[\"early_stopping\"]:\n",
    "        ret += \"-ES\" + str(row[\"early_stopping\"])\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Featurization\"] = df.apply(lambda x: get_row_featurization(x), axis=1)\n",
    "df.groupby([\"Featurization\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "#resdata = defaultdict()\n",
    "c1reskeys = []\n",
    "c2reskeys = []\n",
    "for key in df.keys():\n",
    "    if 'Final-Relative-TotalPPCost-' in key:\n",
    "        if \"train\" in key:\n",
    "            continue\n",
    "        if 'Final-Relative-TotalPPCost-val' == key:\n",
    "            continue\n",
    "        if \"C2\" in key:\n",
    "            c2reskeys.append(key)\n",
    "        else:\n",
    "            c1reskeys.append(key)\n",
    "print(len(c2reskeys), len(c1reskeys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df[[\"train_tmps\"] + c1reskeys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1reskeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdata = defaultdict(list)\n",
    "for idx,row in df.iterrows():\n",
    "    if row[\"train_tmps\"] == \"4a\":\n",
    "        continue\n",
    "        \n",
    "    resdata[\"Featurization\"].append(row[\"Featurization\"])\n",
    "    resdata[\"Train\"].append(row[\"train_tmps\"])\n",
    "    for k in c1reskeys:\n",
    "        if \"4a\" in k:\n",
    "            continue\n",
    "        if \"job\" in k:\n",
    "            continue\n",
    "        if np.isnan(row[k]):\n",
    "            continue\n",
    "        if \"val-\" in k:\n",
    "            tmp_name = k[k.rfind(\"-\")+1:]\n",
    "            assert tmp_name == row[\"train_tmps\"]\n",
    "            resdata[row[\"train_tmps\"]].append(row[k])\n",
    "        else:\n",
    "            tmp_name = k[k.rfind(\"-\")+1:]\n",
    "            resdata[tmp_name].append(row[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgc1 = {}\n",
    "for k in c1reskeys:\n",
    "    k = k.replace(\"test\", \"train\")\n",
    "    if \"job\" in k:\n",
    "        continue\n",
    "    if \"train\" not in k:\n",
    "        continue\n",
    "    tmp = pgdf[~pgdf[k].isna()]\n",
    "    if np.isnan(tmp[k].mean()):\n",
    "        continue\n",
    "    #print(k, tmp[k].mean(), tmp[k].min())\n",
    "    tmp_name = k[k.rfind(\"-\")+1:]\n",
    "    pgc1[tmp_name] = tmp[k].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf = pd.DataFrame(resdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in resdf.keys():\n",
    "#     if k in pgc1:\n",
    "#         resdf[k] /= pgc1[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(resdf[\"Featurization\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(resdf[\"Featurization\"]))\n",
    "rdf2 = resdf[resdf[\"Featurization\"].isin(['Default-ES1', 'Default-ES2', 'Default-dropout-0.8-ES1'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf2.groupby([\"Featurization\", \"Train\"]).mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYS = [\"1a\", \"2a\", \"2b\", \"2c\", \"3a\", \"5a\", \"6a\", \"7a\", \"8a\"]\n",
    "rd3 = rdf2[KEYS] > 2\n",
    "print(rd3.sum())\n",
    "rd3 = rdf2[KEYS] < 1\n",
    "print(rd3.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=rdf2, x=\"Train\", y=\"test\", hue=\"Featurization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spectacular-nylon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
